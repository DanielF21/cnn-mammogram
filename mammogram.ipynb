{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_gdrive = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "if use_gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  data_dir = \"/content/drive/MyDrive/notebooks_data\"\n",
        "else:\n",
        "  data_dir = \"./data\"\n",
        "\n",
        "downloads_dir = data_dir + '/downloads'\n",
        "datasets_dir = data_dir + '/datasets'\n",
        "models_dir = data_dir + '/models'\n",
        "pretrained_models = data_dir + '/pretrained_models'\n",
        "q2c_data_dir = data_dir + '/q2c_data'\n",
        "\n",
        "os.makedirs(downloads_dir, exist_ok=True)\n",
        "os.makedirs(datasets_dir, exist_ok=True)\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(pretrained_models, exist_ok=True)\n",
        "os.makedirs(q2c_data_dir, exist_ok=True)\n",
        "\n",
        "mias_dataset_dir = datasets_dir + '/mias_dataset'\n",
        "external_dataset_dir = datasets_dir + '/external_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STIAimMmXUSf"
      },
      "outputs": [],
      "source": [
        "# Download MIAS dataset\n",
        "!wget http://6.869.csail.mit.edu/sp22/psets/pset6_serc_data/mias_dataset.zip -O {downloads_dir}/mias_dataset.zip\n",
        "!wget http://6.869.csail.mit.edu/sp22/psets/pset6_serc_data/external_dataset.zip -O {downloads_dir}/external_dataset.zip\n",
        "!wget http://6.869.csail.mit.edu/sp22/psets/pset6_serc_data/q2c_data.zip -O {downloads_dir}/q2c_data.zip\n",
        "\n",
        "!unzip -o {downloads_dir}'/mias_dataset.zip' -d {mias_dataset_dir}\n",
        "!unzip -o {downloads_dir}'/external_dataset.zip' -d {external_dataset_dir}\n",
        "!unzip -o {downloads_dir}'/q2c_data.zip' -d {q2c_data_dir}\n",
        "\n",
        "!rm -rf {downloads_dir}\n",
        "\n",
        "!wget http://6.869.csail.mit.edu/sp22/psets/pset6_serc_data/pretreained_models/instructors_model/model.pth -O {pretrained_models}/instructors_model.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBOaBfJkg8Kb"
      },
      "source": [
        "This code was adapted from <https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQslchnXg8Kc"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ8_lvaFg8Kc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "!pip install tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import copy\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU!\")\n",
        "else:\n",
        "    print(\"WARNING: Could not find GPU! Using CPU only\")\n",
        "    print(\"You may want to try to use the GPU in Google Colab by clicking in:\")\n",
        "    print(\"Runtime > Change Runtime type > Hardware accelerator > GPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC-GQcIjg8Kd"
      },
      "source": [
        "First, we need to initialize an empty model, that will input an image, and output a classification. Each model is a little different, so we'll make a helper function that takes in an architecture name, and outputs a model. This is only meant as a guideline, and you can try using different models! `torchvision.models` has other common architectures, and variations on these (like ResNet-50 and ResNet-101), so you may want to try those out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WB5uFRkg8Kd"
      },
      "outputs": [],
      "source": [
        "def initialize_model(model_name, num_classes, resume_from = None, use_pretrained = False):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    # The model (nn.Module) to return\n",
        "    model_ft = None\n",
        "    # The input image is expected to be (input_size, input_size)\n",
        "    input_size = 0\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"resnet50\":\n",
        "        \"\"\" Resnet50\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Invalid model name!\")\n",
        "\n",
        "    if resume_from is not None:\n",
        "        print(\"Loading weights from %s\" % resume_from)\n",
        "        model_ft.load_state_dict(torch.load(resume_from))\n",
        "\n",
        "    return model_ft, input_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inFD-G_ug8Kf"
      },
      "source": [
        "### Data Loading\n",
        "\n",
        "With the input size from the model, we can now load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKhoANULg8Kf"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.functional import to_grayscale\n",
        "\n",
        "def get_image_transforms():\n",
        "    # How to transform the image when you are loading them.\n",
        "    # you'll likely want to mess with the transforms on the training set.\n",
        "\n",
        "    # We convert the image to a [C,H,W] tensor, then normalize it to values with a given mean/stdev. These normalization constants\n",
        "    # are derived from the mean/stdev of the ImageNet training set which was used to pretrain our models.\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    return transform\n",
        "\n",
        "def get_dataloaders(dataset_dir, input_size, batch_size, shuffle = True, transform=get_image_transforms()):\n",
        "    data_transforms = {\n",
        "        'train': transform,\n",
        "        'val': transform,\n",
        "        'test': transform\n",
        "    }\n",
        "    # Create training, validation and test datasets\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(dataset_dir, x), data_transforms[x]) for x in data_transforms.keys()}\n",
        "    # Create training, validation and test dataloaders\n",
        "    # Never shuffle the test set\n",
        "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=False if x != 'train' else shuffle, num_workers=4) for x in data_transforms.keys()}\n",
        "    return dataloaders_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3YhVPgNg8Kg"
      },
      "source": [
        "### Training\n",
        "Next, let's make a helper function that trains the given model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSgcSULBg8Kh"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, save_dir = None, save_all_epochs=False, num_epochs=25):\n",
        "    '''\n",
        "    model: The NN to train\n",
        "    dataloaders: A dictionary containing at least the keys\n",
        "                 'train','val' that maps to Pytorch data loaders for the dataset\n",
        "    criterion: The Loss function\n",
        "    optimizer: The algorithm to update weights\n",
        "               (Variations on gradient descent)\n",
        "    num_epochs: How many epochs to train for\n",
        "    save_dir: Where to save the best model weights that are found,\n",
        "              as they are found. Will save to save_dir/weights_best.pt\n",
        "              Using None will not write anything to disk\n",
        "    save_all_epochs: Whether to save weights for ALL epochs, not just the best\n",
        "                     validation error epoch. Will save to save_dir/weights_e{#}.pt\n",
        "    '''\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    train_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            # TQDM has nice progress bars\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # torch.max outputs the maximum value, and its index\n",
        "                    # Since the input is batched, we take the max along axis 1\n",
        "                    # (the meaningful outputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backprop + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc)\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "            if save_all_epochs:\n",
        "                torch.save(model.state_dict(), os.path.join(save_dir, f'weights_{epoch}.pt'))\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # save and load best model weights\n",
        "    torch.save(best_model_wts, os.path.join(save_dir, 'weights_best_val_acc.pt'))\n",
        "    torch.save(model.state_dict(), os.path.join(save_dir, 'weights_last.pt'.format(epoch)))\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history, train_acc_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKECnWtqg8Kj"
      },
      "source": [
        "### Optimizer & Loss\n",
        "We need a loss function, and an optimization function to use to try to reduce that loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rigJ--Oeg8Kl"
      },
      "outputs": [],
      "source": [
        "def make_optimizer(model, learning_rate, print_parameters=False):\n",
        "    # Get all the parameters\n",
        "    params_to_update = model.parameters()\n",
        "    if print_parameters:\n",
        "      print(\"Params to learn:\")\n",
        "      for name, param in model.named_parameters():\n",
        "          if param.requires_grad == True:\n",
        "              print(\"\\t\",name)\n",
        "\n",
        "\n",
        "    optimizer = optim.SGD(params_to_update, lr=learning_rate, momentum=0.9)\n",
        "    return optimizer\n",
        "\n",
        "def get_loss():\n",
        "    # Create an instance of the loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    return criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiJMbW15g8Km"
      },
      "source": [
        "### Parameters\n",
        "\n",
        "Our data is conveniently set up to follow the expected format of the  `ImageFolder <https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder>`__\n",
        "dataset class, rather than writing our own custom dataset.\n",
        "\n",
        "The ``model_name`` input is the name of the model you wish to use. We've provided starter code that initializes these models using provided models in TorchVision (a PyTorch library)\n",
        "\n",
        "The code as is supports the following values: [resnet, alexnet, vgg, squeezenet, densenet]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeeXTYlKg8Km"
      },
      "outputs": [],
      "source": [
        "model_name = 'densenet'\n",
        "\n",
        "# Number of classes in the dataset, normal, benign, malignant\n",
        "num_classes = 3\n",
        "\n",
        "batch_size = 32\n",
        "shuffle_datasets = True\n",
        "num_epochs = 30\n",
        "learning_rate = 0.001\n",
        "\n",
        "### IO\n",
        "# Path to a model file to use to start weights at\n",
        "resume_from = None\n",
        "\n",
        "# Whether to use a pretrained model, trained for classification in Imagenet-1k\n",
        "pretrained = False\n",
        "\n",
        "# Save all epochs so that you can select the model from a particular epoch\n",
        "save_all_epochs = False\n",
        "\n",
        "# Whether to use early stopping (load the model with best accuracy), or not\n",
        "early_stopping = True\n",
        "\n",
        "# Directory to save weights to\n",
        "save_dir = models_dir + '/trained_model_1'\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfvtMRQ6g8Km"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71,
          "referenced_widgets": [
            "400e91dd0a4142b683979e4b4c96d094"
          ]
        },
        "id": "xPXX3aEdg8Kn",
        "outputId": "751446db-1bb3-402a-ee2e-566353d35cb2",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "----------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "400e91dd0a4142b683979e4b4c96d094",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/77 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize the model for this run\n",
        "# train model_1\n",
        "model_1, input_size = initialize_model(model_name = model_name, num_classes = num_classes, resume_from=resume_from, use_pretrained=pretrained)\n",
        "dataloaders = get_dataloaders(mias_dataset_dir, input_size, batch_size, shuffle_datasets)\n",
        "criterion = get_loss()\n",
        "\n",
        "# Move the model to the gpu if needed\n",
        "model_1 = model_1.to(device)\n",
        "\n",
        "optimizer_1 = make_optimizer(model_1, learning_rate)\n",
        "\n",
        "# Train the model!\n",
        "trained_model_1, validation_history_1, train_history_1 = train_model(model=model_1,\n",
        "                                                                     dataloaders=dataloaders,\n",
        "                                                                     criterion=criterion,\n",
        "                                                                     optimizer=optimizer_1,\n",
        "                                                                     save_dir=save_dir,\n",
        "                                                                     save_all_epochs=save_all_epochs,\n",
        "                                                                     num_epochs=num_epochs)\n",
        "del model_1, optimizer_1, trained_model_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxxaZu-5SWtO"
      },
      "source": [
        "### Load trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBt3EbutF7YR"
      },
      "outputs": [],
      "source": [
        "if early_stopping:\n",
        "  weights_file = save_dir + '/weights_best_val_acc.pt'\n",
        "else:\n",
        "  weights_file = save_dir + '/weights_last.pt'\n",
        "model_yours, _ = initialize_model(model_name = model_name, num_classes = num_classes, resume_from=resume_from, use_pretrained=pretrained)\n",
        "\n",
        "\n",
        "model_yours = model_yours.to(device)\n",
        "model_yours.load_state_dict(torch.load(weights_file))\n",
        "\n",
        "model_inst = torch.load(pretrained_models + '/instructors_model.pth')\n",
        "model_inst = model_inst.to(device)\n",
        "\n",
        "# set models to eval mode\n",
        "model_yours = model_yours.eval()\n",
        "model_inst = model_inst.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89kemy1Pg8Kn"
      },
      "source": [
        "\n",
        "Now that we've trained a model, we would like to use it for inference on the test data.\n",
        "We will use a function that can compute top-k performance (k = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nlkyj8qhg8Kn"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion, is_labelled = False, generate_labels = True, k = 5):\n",
        "    # If is_labelled, we want to compute loss, top-1 accuracy and top-5 accuracy\n",
        "    # If generate_labels, we want to output the actual labels\n",
        "    # Set the model to evaluate mode\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    running_top1_correct = 0\n",
        "    running_top5_correct = 0\n",
        "    predicted_labels = []\n",
        "    gt_labels = []\n",
        "\n",
        "    # Iterate over data.\n",
        "    # TQDM has nice progress bars\n",
        "    for inputs, labels in tqdm(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        tiled_labels = torch.stack([labels.data for i in range(k)], dim=1)\n",
        "        # Makes this to calculate \"top 5 prediction is correct\"\n",
        "        # [[label1 label1 label1 label1 label1], [label2 label2 label2 label label2]]\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(False):\n",
        "            # Get model outputs and calculate loss\n",
        "            outputs = model(inputs)\n",
        "            if is_labelled:\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # torch.topk outputs the maximum values, and their indices\n",
        "            # Since the input is batched, we take the max along axis 1\n",
        "            # (the meaningful outputs)\n",
        "            _, preds = torch.topk(outputs, k=k, dim=1)\n",
        "            if generate_labels:\n",
        "                # We want to store these results\n",
        "                nparr = preds.cpu().detach().numpy()\n",
        "                predicted_labels.extend([list(nparr[i]) for i in range(len(nparr))])\n",
        "                gt_labels.extend(np.array(labels.cpu()))\n",
        "\n",
        "        if is_labelled:\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            # Check only the first prediction\n",
        "            running_top1_correct += torch.sum(preds[:, 0] == labels.data)\n",
        "            # Check all 5 predictions\n",
        "            running_top5_correct += torch.sum(preds == tiled_labels)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    # Only compute loss & accuracy if we have the labels\n",
        "    if is_labelled:\n",
        "        epoch_loss = float(running_loss / len(dataloader.dataset))\n",
        "        epoch_top1_acc = float(running_top1_correct.double() / len(dataloader.dataset))\n",
        "        epoch_top5_acc = float(running_top5_correct.double() / len(dataloader.dataset))\n",
        "    else:\n",
        "        epoch_loss = None\n",
        "        epoch_top1_acc = None\n",
        "        epoch_top5_acc = None\n",
        "\n",
        "    # Return everything\n",
        "    return epoch_loss, epoch_top1_acc, gt_labels, predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx-PjTCxg8Ko"
      },
      "outputs": [],
      "source": [
        "# Get data on the validation set\n",
        "# Setting this to false will be a little bit faster\n",
        "generate_validation_labels = True\n",
        "val_loss_yours, val_top1_yours, _, val_labels_yours = evaluate(model_yours, dataloaders['val'], criterion, is_labelled = True, generate_labels = generate_validation_labels, k = 1)\n",
        "# Get predictions for the test set\n",
        "test_loss_yours, test_top1_yours, _, test_labels_yours = evaluate(model_yours, dataloaders['test'], criterion, is_labelled = True, generate_labels = generate_validation_labels, k = 1)\n",
        "\n",
        "val_loss_inst, val_top1_inst, _, val_labels_inst = evaluate(model_inst, dataloaders['val'], criterion, is_labelled = True, generate_labels = generate_validation_labels, k = 1)\n",
        "# Get predictions for the test set\n",
        "test_loss_inst, test_top1_inst, _, test_labels_inst = evaluate(model_inst, dataloaders['test'], criterion, is_labelled = True, generate_labels = generate_validation_labels, k = 1)\n",
        "\n",
        "print(\"Your Trained model: \")\n",
        "print(\"Val Top-1 Accuracy: {}\".format(val_top1_yours))\n",
        "print(\"Test Top-1 Accuracy: {}\".format(test_top1_yours))\n",
        "\n",
        "print(\"Instructors model: \")\n",
        "print(\"Val Top-1 Accuracy: {}\".format(val_top1_inst))\n",
        "print(\"Test Top-1 Accuracy: {}\".format(test_top1_inst))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwlV_tsE99oV"
      },
      "outputs": [],
      "source": [
        "model = model_inst\n",
        "# model = model_yours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8igSXYxd5e6R"
      },
      "outputs": [],
      "source": [
        "# Wrapper to easily evaulate a model given a model and the set of dataloaders\n",
        "def get_eval_results(model, dataloaders):\n",
        "    model.eval()\n",
        "    true_label_list = []\n",
        "    outputs_list = []\n",
        "    predicted_label_list = []\n",
        "    original_image_list = []\n",
        "\n",
        "    # TQDM has nice progress bars\n",
        "    for inputs, labels in tqdm(dataloaders['test']):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        with torch.set_grad_enabled(False):\n",
        "            # Get model outputs and calculate loss\n",
        "            outputs = model(inputs)\n",
        "            true_label_list.append(labels)\n",
        "            original_image_list.append(inputs)\n",
        "            outputs_list.append(outputs)\n",
        "            _, preds = torch.topk(outputs, k=1, dim=1)\n",
        "            predicted_label_list.append(preds)\n",
        "    return torch.concat(true_label_list).unsqueeze(-1).cpu().numpy(), \\\n",
        "           torch.concat(predicted_label_list).cpu().numpy(), \\\n",
        "           torch.softmax(torch.concat(outputs_list), dim=1).cpu().numpy(), \\\n",
        "           torch.concat(original_image_list).cpu().numpy()\n",
        "\n",
        "## Please make sure you understand what outputs means here\n",
        "y_label, y_pred, outputs, inputs =  get_eval_results(model, dataloaders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0-_Xpi-Oqvy"
      },
      "source": [
        "\n",
        "Confusion Matrix\n",
        "\n",
        "The first simple method that we will use to delve deeper into the results is the confusion matrix. Complete the function below and plot your confusion matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYEcYY4O2EH6"
      },
      "outputs": [],
      "source": [
        "### Complete your code here to plot your confusion matrix.\n",
        "### Please avoid using sklearn.metrics.confusion_matrix in your function: build your confusion matrix from scratch! You may, however, want to plot its output to check if you're doing the right thing!\n",
        "### Using helper visualization functions is fine, but don't leave the numbers themselves to sub-packages.\n",
        "### Feel free to import necessary packages.\n",
        "\n",
        "def plot_confusion_matrix(y_label, y_pred, title='Confusion matrix'):\n",
        "    n = np.unique(y_label).shape[0]\n",
        "    matrix = np.zeros((n, n))\n",
        "\n",
        "    # Get numbers from labels\n",
        "    for i in range(len(y_label)):\n",
        "        true_label = y_label[i]\n",
        "        pred_label = y_pred[i]\n",
        "        matrix[true_label, pred_label] += 1\n",
        "\n",
        "    # Plot\n",
        "    plt.imshow(matrix, cmap=plt.cm.Blues)\n",
        "\n",
        "    # Numbers\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            plt.text(j, i, format(matrix[i, j]), color=\"black\")\n",
        "\n",
        "    # Labels\n",
        "    plt.xticks(np.arange(n), ['B', 'M', 'N'])\n",
        "    plt.yticks(np.arange(n), ['B', 'M', 'N'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(title)\n",
        "\n",
        "plot_confusion_matrix(y_label, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOU8QEEVPBe7"
      },
      "source": [
        "Precision-Recall Curve\n",
        "\n",
        "Assume that the malignant class is our positive class, and the rest are negative classes. In this scenario, a positive prediction happens when our model's prediction for class malignant is *above a user-defined threshold*. That means that a True Positive (TP) happens when we have a positive prediction and the ground truth label is malignant. A False Positive (FP) happens when we have a positive prediction and the ground truth label is something other than malignant. True negatives (TN) and false negatives (FN) follow the same logic.\n",
        "\n",
        "Remember that Precision = TP/(TP+FP) and Recall = TP/(TP+FN).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juRxsLYZJKQA"
      },
      "outputs": [],
      "source": [
        "new_labels = []\n",
        "threshold_values = np.linspace(0, 1, 1001)  # 1000 vals\n",
        "\n",
        "# Create new labels\n",
        "new_labels = np.array([\n",
        "    0 if (isinstance(label, np.ndarray) and label[0] in [0, 2]) else 1\n",
        "    for label in y_label\n",
        "])\n",
        "\n",
        "# Initialize recalls and precisions\n",
        "recalls, precisions = [], []\n",
        "\n",
        "for threshold_value in threshold_values:\n",
        "    binary_predictions = (outputs[:, 1] >= threshold_value)\n",
        "    t_pos = np.sum(binary_predictions * new_labels)\n",
        "    f_pos = np.sum(binary_predictions * (1 - new_labels))\n",
        "    f_neg = np.sum((1 - binary_predictions) * new_labels)\n",
        "    \n",
        "    recalls.append(t_pos / (t_pos + f_neg))\n",
        "    precisions.append(t_pos / (t_pos + f_pos + 1e-100))\n",
        "\n",
        "# Plot the recall vs precision curve\n",
        "plt.plot(recalls, precisions)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Recall Precision Curve\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn8DvSZBPfBu"
      },
      "source": [
        "In the following code snippet, we use the following pytorch package that implements different variations of CAM:\n",
        "https://github.com/jacobgil/pytorch-grad-cam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ56Koj9D_-h"
      },
      "outputs": [],
      "source": [
        "!pip install grad-cam\n",
        "\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buxAeJL-DmAr"
      },
      "outputs": [],
      "source": [
        "def plot_cams(target_dataloaders, cam_method=GradCAM, class_id='gt'):\n",
        "  assert class_id in ['gt', 'pred'] or type(class_id) is int and class_id < 3\n",
        "  for split in ['train', 'val', 'test']:\n",
        "    target_layers = [model.layer4[-1]]\n",
        "    fig, axs = plt.subplots(2, 6, figsize=(14, 7))\n",
        "    fig.suptitle(\"Examples split {}, class {}\".format(split, class_id), fontsize=16)\n",
        "\n",
        "    split_dataset = target_dataloaders[split].dataset\n",
        "    indices_per_class = defaultdict(list)\n",
        "    for i, (_, c) in enumerate(split_dataset.imgs):\n",
        "      indices_per_class[c].append(i)\n",
        "\n",
        "    random.seed(1337)\n",
        "    indices = []\n",
        "    for c in range(3):\n",
        "      indices.extend(random.sample(indices_per_class[c], 4))\n",
        "\n",
        "    for dataset_i, ax in zip(indices, axs.flatten()):\n",
        "      input_tensor, class_idx = split_dataset[dataset_i]\n",
        "      input_tensor = input_tensor[None,...].cuda()\n",
        "\n",
        "      # Construct the CAM object once, and then re-use it on many images:\n",
        "      cam = cam_method(model=model, target_layers=target_layers, use_cuda=not device == 'cpu')\n",
        "      pred_class_idx = model(input_tensor).argmax()\n",
        "\n",
        "      # We have to specify the target we want to generate\n",
        "      # the Class Activation Maps for\n",
        "      if type(class_id) is int:\n",
        "        target_class_id = class_id\n",
        "      else:\n",
        "        target_class_id = pred_class_idx if class_id == 'pred' else class_idx\n",
        "      targets = [ClassifierOutputTarget(target_class_id)]\n",
        "\n",
        "      # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
        "      grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "      # In this example grayscale_cam has only one image in the batch:\n",
        "      grayscale_cam = grayscale_cam[0, :]\n",
        "      rgb_image = np.array(input_tensor[0].cpu())\n",
        "      rgb_image = (rgb_image - rgb_image.min())/ (rgb_image.max() - rgb_image.min())\n",
        "      visualization = show_cam_on_image(rgb_image.transpose((1,2,0)), grayscale_cam, use_rgb=True)\n",
        "\n",
        "      ax.set_title('True : %s\\n Predicted: %s' %(split_dataset.classes[class_idx], split_dataset.classes[pred_class_idx]))\n",
        "      ax.imshow(visualization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4KSEF-QPrHG"
      },
      "outputs": [],
      "source": [
        "# Substitute GradCAM for one of the following, to test other methods:\n",
        "# GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "# Also substitute class_id for pred, or a class id in [0,1,2] to check different output.\n",
        "plot_cams(dataloaders, cam_method=GradCAM, class_id='gt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
